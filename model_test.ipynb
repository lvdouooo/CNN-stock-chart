{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24127738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebdc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备：{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a623fa",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca19df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 读取主数据和锚点文件\n",
    "df = pd.read_feather('test_data.feather')\n",
    "anchors = pd.read_feather('trading_days_anchor_2001_2019.feather')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "anchors['date'] = pd.to_datetime(anchors['date'])\n",
    "\n",
    "# 2. 合并锚点信息\n",
    "df = df.merge(\n",
    "    anchors[['date', 'anchor_5', 'anchor_20', 'anchor_60']],\n",
    "    on=['date'],\n",
    "    how='left'\n",
    ").sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# 3. 定义每种窗口的配置：窗口长度 / 锚点列 / 输出路径 / 输出标签文件\n",
    "configs = [\n",
    "    (5,  'anchor_5',  './charts_test/5d_charts',  './labels_test/image_labels_i5.feather'),\n",
    "    (20, 'anchor_20', './charts_test/20d_charts', './labels_test/image_labels_i20.feather'),\n",
    "    (60, 'anchor_60', './charts_test/60d_charts', './labels_test/image_labels_i60.feather'),\n",
    "]\n",
    "\n",
    "for window, anchor_col, img_dir, out_feather in configs:\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(out_feather), exist_ok=True)\n",
    "\n",
    "    image_labels = []\n",
    "\n",
    "    for id_val, grp in df.groupby('id'):\n",
    "        grp = grp.reset_index(drop=True)\n",
    "        # 找到所有锚点行索引\n",
    "        idxs = grp.index[grp[anchor_col] == 1.0].tolist()\n",
    "\n",
    "        for idx in idxs:\n",
    "            # 前面必须有 window-1 条数据\n",
    "            if idx >= window - 1:\n",
    "                win = grp.iloc[idx - (window - 1): idx + 1]\n",
    "\n",
    "                # 计算三个 horizon 的 label：看窗口末期的 ret_Xd 是否 > 0\n",
    "                label_5  = int(win['ret_5d'].iloc[-1]  > 0)\n",
    "                label_20 = int(win['ret_20d'].iloc[-1] > 0)\n",
    "                label_60 = int(win['ret_60d'].iloc[-1] > 0)\n",
    "\n",
    "                # 锚点日期（窗口最后一天）\n",
    "                anchor_date = pd.to_datetime(win['date'].iloc[-1]).strftime('%Y%m%d')\n",
    "\n",
    "                # 对应的图像路径\n",
    "                image_path = os.path.join(img_dir, f'id_{id_val}_{anchor_date}.png')\n",
    "\n",
    "                if os.path.exists(image_path):\n",
    "                    image_labels.append({\n",
    "                        'image_path': image_path,\n",
    "                        'id':         id_val,\n",
    "                        'date':       win['date'].iloc[-1],\n",
    "                        'label_5':    label_5,\n",
    "                        'label_20':   label_20,\n",
    "                        'label_60':   label_60,\n",
    "                    })\n",
    "\n",
    "    # 保存标签\n",
    "    labels_df = pd.DataFrame(image_labels)\n",
    "    labels_df.to_feather(out_feather)\n",
    "    print(f\"{window}d 图像标签已生成并保存到 {out_feather}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908c3e6",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e729c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN5DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN5DModel, self).__init__()\n",
    "  \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5, 3), stride=(1, 1), dilation=(1, 1), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))  # 输出尺寸: (64, 16, 15)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5)  # 在全连接层前应用Dropout\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(15360, 2)\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        self.model = nn.Sequential(self.block1, self.block2, self.fc)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CNN20DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 卷积块1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5, 3), stride=(3, 1), dilation=(2, 1), padding=(3, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        \n",
    "        # 卷积块2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 3), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        \n",
    "        # 卷积块3（包含Flatten和Dropout）\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, (5, 3), padding=(3, 1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5)  # 全连接层前的Dropout\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(46080, 2)\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.block1,\n",
    "            self.block2,\n",
    "            self.block3,\n",
    "            self.fc\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"应用Xavier初始化\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CNN60DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN60DModel, self).__init__()\n",
    "        \n",
    "        # 第一个 CNN 构建模块\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1), dilation=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))  # 高度减半至48，宽度保持180\n",
    "        )\n",
    "\n",
    "        # 第二个 CNN 构建模块\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))  # 高度减半至24，宽度保持180\n",
    "        )\n",
    "\n",
    "        # 第三个 CNN 构建模块\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))  # 高度减半至12，宽度保持180\n",
    "        )\n",
    "\n",
    "        # 第四个 CNN 构建模块（关键修改）\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 3), stride=(2, 3)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5)  # 全连接层前应用Dropout\n",
    "        )\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(184320, 2)\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.block1,\n",
    "            self.block2,\n",
    "            self.block3,\n",
    "            self.block4,\n",
    "            self.fc\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"应用Xavier初始化\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN5DModel()\n",
    "model = model.to(device)  # 将模型移动到 GPUc\n",
    "model.eval()  # 设置模型为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe38923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN5DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i5r5.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPUc\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i5.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/5d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i5.feather')\n",
    "new_df['pre_label_5'] = new_df['image_path'].map(predictions)\n",
    "new_df['5_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['5_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_5'] == new_df['label_5']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i5.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished = pd.read_feather('./labels_test/image_labels_i5.feather')\n",
    "df_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN5DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i5r20.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i5.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/5d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i5.feather')\n",
    "new_df['pre_label_20'] = new_df['image_path'].map(predictions)\n",
    "new_df['20_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['20_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_20'] == new_df['label_20']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i5.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN5DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i5r60.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i5.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/5d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i5.feather')\n",
    "new_df['pre_label_60'] = new_df['image_path'].map(predictions)\n",
    "new_df['60_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['60_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_60'] == new_df['label_60']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i5.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN20DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i20r5.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i20.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/20d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i20.feather')\n",
    "new_df['pre_label_5'] = new_df['image_path'].map(predictions)\n",
    "new_df['5_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['5_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_5'] == new_df['label_5']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i20.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e39693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN20DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i20r20.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i20.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/20d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i20.feather')\n",
    "new_df['pre_label_20'] = new_df['image_path'].map(predictions)\n",
    "new_df['20_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['20_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_20'] == new_df['label_20']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i20.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be542b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN20DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i20r60.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i20.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/20d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i20.feather')\n",
    "new_df['pre_label_60'] = new_df['image_path'].map(predictions)\n",
    "new_df['60_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['60_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_60'] == new_df['label_60']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i20.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82325c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN60DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i60r5.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i60.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/60d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i60.feather')\n",
    "new_df['pre_label_5'] = new_df['image_path'].map(predictions)\n",
    "new_df['5_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['5_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_5'] == new_df['label_5']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i60.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989db51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN60DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i60r20.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i60.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/60d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i60.feather')\n",
    "new_df['pre_label_20'] = new_df['image_path'].map(predictions)\n",
    "new_df['20_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['20_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_20'] == new_df['label_20']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i60.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "model = CNN60DModel()\n",
    "model.load_state_dict(torch.load('./labels_train/best_model_i60r60.pth'))\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 定义新的数据集类\n",
    "class StockImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_frame = pd.read_feather(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels_frame.iloc[idx]['image_path'].split('/')[-1])\n",
    "        image = Image.open(img_path)  # 读取图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # 返回图像和路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 创建新的数据集和数据加载器\n",
    "dataset = StockImageDataset(\n",
    "    csv_file='./labels_test/image_labels_i60.feather',  # 新数据集的标签文件\n",
    "    img_dir='./charts_test/60d_charts',  # 新数据集的图像文件夹\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "new_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 在新数据集上生成预测标签和概率\n",
    "predictions = {}\n",
    "probabilities_0 = {}  # 存储类别 0 的概率\n",
    "probabilities_1 = {}  # 存储类别 1 的概率\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data, paths in tqdm(new_loader, desc=\"Generating Predictions\"):\n",
    "        data = data.to(device)\n",
    "        output = model(data)  # 模型输出，形状为 [batch_size, num_classes]\n",
    "        probs = torch.softmax(output, dim=1)  # 使用 softmax 将输出转换为概率\n",
    "        pred = output.argmax(dim=1).cpu().numpy()  # 获取预测标签\n",
    "\n",
    "        for path, p, prob in zip(paths, pred, probs.cpu().numpy()):\n",
    "            predictions[path] = int(p)\n",
    "            probabilities_0[path] = prob[0]  # 类别 0 的概率\n",
    "            probabilities_1[path] = prob[1]  # 类别 1 的概率\n",
    "\n",
    "# 将预测结果和概率添加到原始标签文件\n",
    "new_df = pd.read_feather('./labels_test/image_labels_i60.feather')\n",
    "new_df['pre_label_60'] = new_df['image_path'].map(predictions)\n",
    "new_df['60_prob_0'] = new_df['image_path'].map(probabilities_0)  # 类别 0 的概率\n",
    "new_df['60_prob_1'] = new_df['image_path'].map(probabilities_1)  # 类别 1 的概率\n",
    "\n",
    "# 计算预测正确率\n",
    "correct_predictions = (new_df['pre_label_60'] == new_df['label_60']).sum()\n",
    "total_predictions = len(new_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"预测完成，正确率为：{accuracy:.2%}\")\n",
    "\n",
    "# 覆盖保存到原文件\n",
    "new_df.to_feather('./labels_test/image_labels_i60.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
