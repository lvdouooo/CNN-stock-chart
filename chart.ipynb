{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "导入所需库\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cf3fc",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f73da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "处理原始数据\n",
    "1. 下载数据：https://wrds-www.wharton.upenn.edu/，包含列：PERMNO, HdrCUSIP, PrimaryExch, USIncFlg, Ticker, PERMCO, DlyCalDt, DlyCap, DlyRetx, DlyVol, DlyClose, DlyLow, DlyHigh, DlyOpen\n",
    "2. 计算过去N日移动平均（5天，20天，60天），计算未来N日累积收益率（5天，20天，60天）\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('./your/path.csv')\n",
    "df = df.rename(columns = {'PERMNO':'id',\n",
    "                        'DlyCalDt':'date',\n",
    "                        'DlyCap':'cap',\n",
    "                        'DlyRetx':'ret',\n",
    "                        'DlyVol':'vol',\n",
    "                        'DlyClose':'close',\n",
    "                        'DlyLow':'low',\n",
    "                        'DlyHigh':'high',\n",
    "                        'DlyOpen':'open',})\n",
    "df = df.drop(['HdrCUSIP', 'Ticker', 'PERMCO','PrimaryExch','USIncFlg'], axis = 1)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by = ['id', 'date'])\n",
    "df = df[['id', 'date', 'cap', 'open', 'close', 'high', 'low', 'vol', 'ret']]\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['id', 'date']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df['close1'] = df['close']\n",
    "df['close1'] = df['close1'].fillna(0)\n",
    "\n",
    "def calculate_ma(group):\n",
    "    group = group.sort_values(by = 'date')\n",
    "    group['ma5'] = group['close1'].rolling(window=5).mean().round(3)\n",
    "    group['ma20'] = group['close1'].rolling(window=20).mean().round(3)\n",
    "    group['ma60'] = group['close1'].rolling(window=60).mean().round(3)\n",
    "    return group\n",
    "df = df.groupby('id', group_keys=False).apply(calculate_ma)\n",
    "\n",
    "def calculate_returns(group):\n",
    "    group = group.sort_values(by = ['id', 'date'])\n",
    "    for i in [5, 20, 60]:\n",
    "        group[f'ret_{i}d'] = (\n",
    "            group['ret']\n",
    "            .rolling(i)\n",
    "            .apply(lambda r: (1 + r).prod() - 1)\n",
    "            .shift(-i)  # 未来i日收益（不含当日）\n",
    "        )\n",
    "    return group\n",
    "df = df.groupby('id', group_keys=False).apply(calculate_returns)\n",
    "\n",
    "df.drop(['close1'], axis = 1, inplace = True)\n",
    "df = df.sort_values(by = ['id', 'date'])\n",
    "df.to_feather('./data/train_data.feather')\n",
    "# df.to_feather('./data/test_data.feather')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6782a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "下载日历\n",
    "'''\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "df = nyse.valid_days('1993-01-01', '2020-12-31')\n",
    "df = pd.DataFrame({'date': df})\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['anchor_5'] = np.nan\n",
    "df['anchor_20'] = np.nan\n",
    "df['anchor_60'] = np.nan\n",
    "\n",
    "# 计算 anchor_5 和 anchor_20\n",
    "grouped_month = df.groupby([df['date'].dt.year, df['date'].dt.month])\n",
    "for (y, m), group in grouped_month:\n",
    "    idx = group.index.tolist()\n",
    "    # anchor_20: 每月最后一个交易日标 1\n",
    "    df.loc[idx[-1], 'anchor_20'] = 1\n",
    "    # anchor_5: 从月末开始，每隔 5 个交易日标 1\n",
    "    for pos in range(len(idx)-1, -1, -5):\n",
    "        df.loc[idx[pos], 'anchor_5'] = 1\n",
    "\n",
    "# 计算 anchor_60\n",
    "grouped_year = df.groupby(df['date'].dt.year)\n",
    "for y, group in grouped_year:\n",
    "    for m in [3, 6, 9, 12]:\n",
    "        month_group = group[group['date'].dt.month == m]\n",
    "        if not month_group.empty:\n",
    "            last_idx = month_group.index[-1]\n",
    "            df.loc[last_idx, 'anchor_60'] = 1\n",
    "\n",
    "mask1 = (df['date'].dt.year >= 1993) & (df['date'].dt.year <= 2000)\n",
    "df1 = df.loc[mask1].sort_values('date').reset_index(drop=True)\n",
    "df1['date'] = pd.to_datetime(df1['date']).dt.date\n",
    "mask2 = (df['date'].dt.year >= 2001) & (df['date'].dt.year <= 2019)\n",
    "df2 = df.loc[mask2].sort_values('date').reset_index(drop=True)\n",
    "df2['date'] = pd.to_datetime(df2['date']).dt.date\n",
    "df1.to_feather('./data/trading_days_anchor_1993_2000.feather')\n",
    "print(df1.head())\n",
    "df2.to_feather('./data/trading_days_anchor_2001_2019.feather')\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88b434",
   "metadata": {},
   "source": [
    "# Chart Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "绘图函数：\n",
    "    1) 收盘价归一化重建\n",
    "    2) 按比例缩放 open/high/low/ma\n",
    "    3) 价格区和成交量区缩放\n",
    "    4) 逐日绘制高低线、开收、MA 点和成交量\n",
    "    5) 线性插值连接 MA\n",
    "    6) 保存图片\n",
    "    \"\"\"\n",
    "'''\n",
    "\n",
    "def draw_chart(df, save_path,\n",
    "               NUM_DAYS,\n",
    "               IMG_HEIGHT,\n",
    "               PRICE_HEIGHT,\n",
    "               VOL_HEIGHT,\n",
    "               ma_col,\n",
    "               interp_points):\n",
    "\n",
    "    COLUMNS_PER_DAY = 3\n",
    "\n",
    "    # 1. 数据提取\n",
    "    data = {\n",
    "        'open'  : df['open'].values,\n",
    "        'high'  : df['high'].values,\n",
    "        'low'   : df['low'].values,\n",
    "        'close' : df['close'].values,\n",
    "        'volume': df['vol'].values,\n",
    "        'ret'   : df['ret'].values,\n",
    "        ma_col   : df[ma_col].values\n",
    "    }\n",
    "\n",
    "    # 2. 收盘价归一化\n",
    "    norm_close = [1.0]\n",
    "    for t in range(1, NUM_DAYS):\n",
    "        norm_close.append(norm_close[-1] * (1 + data['ret'][t]))\n",
    "    data['close'] = np.array(norm_close)\n",
    "\n",
    "    # 3. 按比例缩放 open/high/low/ma\n",
    "    valid_close = df['close'].replace(0, np.nan).values\n",
    "    scale = data['close'] / valid_close\n",
    "    scale[np.isinf(scale)] = np.nan\n",
    "    for k in ['open', 'high', 'low', ma_col]:\n",
    "        data[k] = data[k] * scale\n",
    "\n",
    "    # 4. 计算价格区上下限\n",
    "    valid_prices = np.concatenate([\n",
    "        data['low'][~np.isnan(data['low'])],\n",
    "        data['open'][~np.isnan(data['open'])],\n",
    "        data['close'][~np.isnan(data['close'])],\n",
    "        data['high'][~np.isnan(data['high'])],\n",
    "        data[ma_col][~np.isnan(data[ma_col])]\n",
    "    ])\n",
    "    price_min = valid_prices.min() if valid_prices.size else 0\n",
    "    price_max = valid_prices.max() if valid_prices.size else 0\n",
    "    price_scale = ((PRICE_HEIGHT - 1) / (price_max - price_min)\n",
    "                   if price_max != price_min else 0)\n",
    "\n",
    "    # 5. 成交量区缩放\n",
    "    valid_vol = data['volume'][~np.isnan(data['volume'])]\n",
    "    vol_max   = valid_vol.max() if valid_vol.size else 0\n",
    "    vol_scale = (VOL_HEIGHT / vol_max) if vol_max else 0\n",
    "\n",
    "    # 6. 初始化画布\n",
    "    img = np.zeros((IMG_HEIGHT, NUM_DAYS * COLUMNS_PER_DAY), dtype=np.uint8)\n",
    "\n",
    "    # 7. 按天绘制\n",
    "    ma_pts = []\n",
    "    for day in range(NUM_DAYS):\n",
    "        l, m, r = day*COLUMNS_PER_DAY, day*COLUMNS_PER_DAY+1, day*COLUMNS_PER_DAY+2\n",
    "\n",
    "        # 高 - 低线\n",
    "        h, lo = data['high'][day], data['low'][day]\n",
    "        if not (np.isnan(h) or np.isnan(lo)):\n",
    "            y_h = int(round((price_max - h) * price_scale))\n",
    "            y_l = int(round((price_max - lo)* price_scale))\n",
    "            img[min(y_h, y_l):max(y_h, y_l)+1, m] = 255\n",
    "\n",
    "        # 开盘、收盘\n",
    "        for col, key in ((l, 'open'), (r, 'close')):\n",
    "            val = data[key][day]\n",
    "            if not np.isnan(val):\n",
    "                y = int(round((price_max - val) * price_scale))\n",
    "                img[y, col] = 255\n",
    "\n",
    "        # MA 点\n",
    "        ma = data[ma_col][day]\n",
    "        if not np.isnan(ma):\n",
    "            y_ma = int(round((price_max - ma) * price_scale))\n",
    "            ma_pts.append((m, y_ma))\n",
    "\n",
    "        # 成交量\n",
    "        vol = data['volume'][day]\n",
    "        if not np.isnan(vol):\n",
    "            h_vol = int(round(vol * vol_scale))\n",
    "            img[IMG_HEIGHT - h_vol:, m] = 255\n",
    "\n",
    "    # 8. 插值连接 MA（线性）\n",
    "    if len(ma_pts) >= 2:\n",
    "        xs, ys = zip(*sorted(ma_pts))\n",
    "        f = interp1d(xs, ys, kind='linear', bounds_error=False)\n",
    "        x_new = np.linspace(xs[0], xs[-1], interp_points)\n",
    "        y_new = f(x_new)\n",
    "        for xi_f, yi_f in zip(x_new, y_new):\n",
    "            if np.isnan(yi_f): \n",
    "                continue\n",
    "            xi, yi = int(round(xi_f)), int(round(yi_f))\n",
    "            if 0 <= xi < img.shape[1] and 0 <= yi < PRICE_HEIGHT:\n",
    "                img[yi, xi] = 255\n",
    "\n",
    "    # 9. 保存\n",
    "    Image.fromarray(img).save(save_path)\n",
    "\n",
    "\n",
    "def Chart5d(df, save_path):\n",
    "    draw_chart(df, save_path,\n",
    "               NUM_DAYS=5,\n",
    "               IMG_HEIGHT=32,\n",
    "               PRICE_HEIGHT=26,\n",
    "               VOL_HEIGHT=6,\n",
    "               ma_col='ma5',\n",
    "               interp_points=100)\n",
    "\n",
    "def Chart20d(df, save_path):\n",
    "    draw_chart(df, save_path,\n",
    "               NUM_DAYS=20,\n",
    "               IMG_HEIGHT=64,\n",
    "               PRICE_HEIGHT=52,\n",
    "               VOL_HEIGHT=12,\n",
    "               ma_col='ma20',\n",
    "               interp_points=200)\n",
    "\n",
    "def Chart60d(df, save_path):\n",
    "    draw_chart(df, save_path,\n",
    "               NUM_DAYS=60,\n",
    "               IMG_HEIGHT=96,\n",
    "               PRICE_HEIGHT=78,\n",
    "               VOL_HEIGHT=18,\n",
    "               ma_col='ma60',\n",
    "               interp_points=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "作图：读取数据，合并锚点信息，按 id+date 排序\n",
    "配置每种窗口的参数，分组处理数据，生成图像\n",
    "'''\n",
    "# 1. 读取数据\n",
    "df = pd.read_feather('./data/train_data.feather')\n",
    "anchor_df = pd.read_feather('./data/trading_days_anchor_1993_2000.feather')\n",
    "\n",
    "# 2. 合并锚点信息到主表\n",
    "df = df.merge(\n",
    "    anchor_df[['date', 'anchor_5', 'anchor_20', 'anchor_60']],\n",
    "    on=['date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. 按 id+date 排序\n",
    "df = df.sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# 4. 配置每种窗口的参数：窗口大小 / 锚点列 / 绘图函数 / 输出目录\n",
    "configs = [\n",
    "    (5,  'anchor_5',  Chart5d,  './charts_train/5d_charts'),\n",
    "    (20, 'anchor_5', Chart20d, './charts_train/20d_charts'),\n",
    "    (60, 'anchor_5', Chart60d, './charts_train/60d_charts'),\n",
    "]\n",
    "\n",
    "for window, anchor_col, chart_func, output_dir in configs:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 分组处理\n",
    "    for id_val, group in df.groupby('id'):\n",
    "        group = group.reset_index(drop=True)\n",
    "        \n",
    "        # 找到所有锚点行的索引\n",
    "        anchor_idxs = group.index[group[anchor_col] == 1.0].tolist()\n",
    "        for idx in anchor_idxs:\n",
    "            # 确保前面有足够的数据\n",
    "            if idx >= (window - 1):\n",
    "                window_df = group.iloc[idx - (window - 1): idx + 1]\n",
    "                \n",
    "                # 格式化锚点日期为 YYYYMMDD\n",
    "                anchor_date = pd.to_datetime(window_df['date'].iloc[-1]).strftime('%Y%m%d')\n",
    "                \n",
    "                # 构造保存路径，后缀 .bat\n",
    "                save_path = os.path.join(\n",
    "                    output_dir,\n",
    "                    f'id_{id_val}_{anchor_date}.png'\n",
    "                )\n",
    "                \n",
    "                # 调用绘图函数\n",
    "                chart_func(window_df, save_path)\n",
    "    \n",
    "    print(f\"{window}d 图像生成完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "随机查看图像和检查\n",
    "'''\n",
    "for i in [5, 20, 60]:\n",
    "    image_folder = f'./charts_train/{i}d_charts'\n",
    "    # image_folder = f'./charts_test/{i}d_charts'\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
    "\n",
    "    random_image = random.choice(image_files)\n",
    "    image_path = os.path.join(image_folder, random_image)\n",
    "    print({image_path})\n",
    "    display(Image(filename=image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d44ff",
   "metadata": {},
   "source": [
    "# Labeling and Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e72b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 读取主数据和锚点文件\n",
    "df = pd.read_feather('train_data.feather')\n",
    "anchors = pd.read_feather('trading_days_anchor_1993_2000.feather')\n",
    "\n",
    "# 2. 合并锚点信息\n",
    "df = df.merge(\n",
    "    anchors[['date', 'anchor_5', 'anchor_20', 'anchor_60']],\n",
    "    on=['date'],\n",
    "    how='left'\n",
    ").sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# 3. 定义每种窗口的配置：窗口长度 / 锚点列 / 输出路径 / 输出标签文件\n",
    "configs = [\n",
    "    (5,  'anchor_5',  './charts_train/5d_charts',  './labels_train/image_labels_i5.feather'),\n",
    "    (20, 'anchor_20', './charts_train/20d_charts', './labels_train/image_labels_i20.feather'),\n",
    "    (60, 'anchor_60', './charts_train/60d_charts', './labels_train/image_labels_i60.feather'),\n",
    "]\n",
    "\n",
    "for window, anchor_col, img_dir, out_feather in configs:\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(out_feather), exist_ok=True)\n",
    "\n",
    "    image_labels = []\n",
    "\n",
    "    for id_val, grp in df.groupby('id'):\n",
    "        grp = grp.reset_index(drop=True)\n",
    "        # 找到所有锚点行索引\n",
    "        idxs = grp.index[grp[anchor_col] == 1.0].tolist()\n",
    "\n",
    "        for idx in idxs:\n",
    "            # 前面必须有 window-1 条数据\n",
    "            if idx >= window - 1:\n",
    "                win = grp.iloc[idx - (window - 1): idx + 1]\n",
    "\n",
    "                # 计算三个 horizon 的 label：看窗口末期的 ret_Xd 是否 > 0\n",
    "                label_5  = int(win['ret_5d'].iloc[-1]  > 0)\n",
    "                label_20 = int(win['ret_20d'].iloc[-1] > 0)\n",
    "                label_60 = int(win['ret_60d'].iloc[-1] > 0)\n",
    "\n",
    "                # 锚点日期（窗口最后一天）\n",
    "                anchor_date = pd.to_datetime(win['date'].iloc[-1]).strftime('%Y%m%d')\n",
    "\n",
    "                # 对应的图像路径\n",
    "                image_path = os.path.join(img_dir, f'id_{id_val}_{anchor_date}.png')\n",
    "\n",
    "                if os.path.exists(image_path):\n",
    "                    image_labels.append({\n",
    "                        'image_path': image_path,\n",
    "                        'id':         id_val,\n",
    "                        'date':       win['date'].iloc[-1],\n",
    "                        'label_5':    label_5,\n",
    "                        'label_20':   label_20,\n",
    "                        'label_60':   label_60,\n",
    "                    })\n",
    "\n",
    "    # 保存标签\n",
    "    labels_df = pd.DataFrame(image_labels)\n",
    "    labels_df.to_feather(out_feather)\n",
    "    print(f\"{window}d 图像标签已生成并保存到 {out_feather}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_and_split(labels_file, label_column, train_file, test_file):\n",
    "    # 读取标签文件\n",
    "    labels_df = pd.read_feather(labels_file)\n",
    "\n",
    "    # 获取标签为 0 和 1 的数据\n",
    "    label_0 = labels_df[labels_df[label_column] == 0]\n",
    "    label_1 = labels_df[labels_df[label_column] == 1]\n",
    "\n",
    "    # 确保选择相同数量的标签为 0 和 1 的样本\n",
    "    num_samples = min(len(label_0), len(label_1))\n",
    "    label_0 = label_0.sample(n=num_samples, random_state=42)\n",
    "    label_1 = label_1.sample(n=num_samples, random_state=42)\n",
    "\n",
    "    # 合并平衡后的数据并打乱\n",
    "    balanced_df = pd.concat([label_0, label_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # 按照 70% 训练集和 30% 测试集划分\n",
    "    train_df, test_df = train_test_split(\n",
    "        balanced_df, train_size=0.7, stratify=balanced_df[label_column], random_state=42\n",
    "    )\n",
    "\n",
    "    # 确保训练集和测试集标签分布均衡\n",
    "    print(f\"训练集标签分布 ({label_column}):\")\n",
    "    print(train_df[label_column].value_counts())\n",
    "    print(f\"\\n测试集标签分布 ({label_column}):\")\n",
    "    print(test_df[label_column].value_counts())\n",
    "\n",
    "    # 保存训练集和测试集到 Feather 文件\n",
    "    train_df.to_feather(train_file)\n",
    "    test_df.to_feather(test_file)\n",
    "\n",
    "    print(f\"数据集 {label_column} 已划分并保存！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [5, 20, 60]\n",
    "labels = [5, 20, 60]\n",
    "\n",
    "for h in horizons:\n",
    "    for l in labels:\n",
    "        balance_and_split(\n",
    "            labels_file = f'./labels_train/image_labels_i{h}.feather',\n",
    "            label_column = f'label_{l}',\n",
    "            train_file = f'./labels_train/train_labels_i{h}r{l}.feather',\n",
    "            test_file  = f'./labels_train/test_labels_i{h}r{l}.feather',\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
